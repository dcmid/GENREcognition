{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Recognition - Milestone 1\n",
    "Darren Midkiff and Cheng-Wei Hu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project aims to identify the genre of music in an audio sample. Features will be extracted from the analog data, and a genre will be predicted using a KNN model, trained on labelled audio samples from the freely available FMA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "The [FMA Dataset](https://github.com/mdeff/fma) is comprised of over 100,000 tracks from 161 genres. In order to make the problem more manageable, we will use the small version of the dataset, which includes 8,000 tracks from 8 top-level genres. The dataset also includes dozens of features -- year released, location of artist, number of listens, etc. Because this project aims to identify genre using only audio signal, all of these features are irrelevant and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_id genre_top\n",
       "0        2   Hip-Hop\n",
       "1        5   Hip-Hop\n",
       "2       10       Pop\n",
       "3      140      Folk\n",
       "4      141      Folk"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read full metadata file\n",
    "metadata = pd.read_csv(\"./fma_metadata/tracks.csv\", skiprows=[0,2], low_memory=False)\n",
    "\n",
    "# drop all tracks that are not in fma_small dataset\n",
    "metadata = metadata[metadata[\"subset\"].eq(\"small\")]\n",
    "# add name to track_id column (missing because of stupid CSV formatting)\n",
    "metadata = metadata.rename(columns={\"Unnamed: 0\": \"track_id\"})\n",
    "# drop all columns that don't relate to genre\n",
    "# we will not have this metadata from the audio file\n",
    "metadata.drop(metadata.columns.difference([\"track_id\",\"genre_top\"]),1,inplace=True)\n",
    "# reset indices accounting for dropped rows\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "# #write only relevant metadata to file for use in training\n",
    "# metadata.to_csv(\"fma_small_genres.csv\")\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hip-Hop' 'Pop' 'Folk' 'Experimental' 'Rock' 'International' 'Electronic'\n",
      " 'Instrumental']\n"
     ]
    }
   ],
   "source": [
    "print(metadata[\"genre_top\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature extraction, we aim to analyze the audio files from the small version of the [FMA Dataset](https://github.com/mdeff/fma). The `fma_small` consists of 8,000 audio files from 8 top-level genres and each file has 30 seconds of audio data. For each file, we extract four features: [Zero Crossing Rate](https://en.wikipedia.org/wiki/Zero-crossing_rate), [Spectral Centroid](https://en.wikipedia.org/wiki/Spectral_centroid), [Spectral Rolloff](https://en.wikipedia.org/wiki/Spectral_slope), and [Mel-Frequency Cepstral Coefficients](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum).\n",
    "\n",
    "\n",
    "In our project, we will use [librosa](https://librosa.org/doc/latest/index.html) to extract features from the raw audio. To make the training data more accessible, we will export all the features into a csv file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the audio file path from the fma_small dataset \n",
    "import os\n",
    "file_names = []\n",
    "for root, dirs, files in os.walk('./fma_small', topdown=False):\n",
    "    for name in files:\n",
    "        if name[-1] != '3':\n",
    "            continue\n",
    "        file_names.append(os.path.join(root, name))\n",
    "# print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to extract the four features from  \n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n",
    "\n",
    "def extract_feature_from_audio(audio_path, should_plot = False, should_print = False):\n",
    "    # load\n",
    "    x , sr = librosa.load(audio_path)\n",
    "    if should_plot:\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.waveplot(x, sr=sr)\n",
    "    \n",
    "    # zero_crossings\n",
    "    zero_crossings = librosa.zero_crossings(x, pad=False)\n",
    "    zero_crossings_sum = sum(zero_crossings)\n",
    "    \n",
    "    if should_print:\n",
    "        print(zero_crossings.shape)\n",
    "        print(zero_crossings)\n",
    "        print(zero_crossings_sum)\n",
    "        print(zero_crossings_sum / len(x))\n",
    "    \n",
    "    # spectral_centroids\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "    \n",
    "    if should_print:\n",
    "        print(spectral_centroids.shape)\n",
    "        print(spectral_centroids)\n",
    "\n",
    "    # Computing the time variable for visualization\n",
    "    # frames = range(len(spectral_centroids))\n",
    "    # t = librosa.frames_to_time(frames)\n",
    "    \n",
    "    # spectral_rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(x, sr=sr)[0]\n",
    "    \n",
    "    if should_print:\n",
    "        print(spectral_rolloff.shape)\n",
    "        print(spectral_rolloff)\n",
    "\n",
    "    # mfccs\n",
    "    mfccs = librosa.feature.mfcc(x, sr=sr)\n",
    "    if should_print:\n",
    "        print(mfccs.shape)\n",
    "        print(mfccs)\n",
    "    #Displaying  the MFCCs:\n",
    "    # librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    \n",
    "    return [zero_crossings, spectral_centroids, spectral_rolloff, mfccs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features from audio files\n",
    "# Some of the audio files are damaged. So we skipped those files.\n",
    "# The damaged files are: './fma_small/099/099134.mp3', './fma_small/108/108925.mp3', './fma_small/133/133297.mp3'\n",
    "\n",
    "train_audio_features_all = []\n",
    "fail_file_names_all = []\n",
    "fail_file_idx_all = []\n",
    "fail_file_names_dict_all = {}\n",
    "\n",
    "for idx, file in enumerate(file_names):\n",
    "    print(idx, file)\n",
    "    try:\n",
    "        single_audio_features = extract_feature_from_audio(file)\n",
    "        row = []\n",
    "        row.append(file.split('/')[-1])\n",
    "        for f in single_audio_features:\n",
    "            row.append(f)\n",
    "        train_audio_features_all.append(row)\n",
    "    except:\n",
    "        print(\"Failed: \", idx, file)\n",
    "        fail_file_names_all.append(file)\n",
    "        fail_file_idx_all.append(file)\n",
    "        fail_file_names_dict_all[file] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the features into a csv files\n",
    "import csv\n",
    "\n",
    "with open('features_all.csv', mode='w') as features_file:\n",
    "    features_file = csv.writer(features_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    features_names = [\"file_name\", \"zero_crossing (zero_crossing_sum & total_frame)\", \"spectral_centroids\", \"spectral_rolloff\", \"mfccs\"]\n",
    "    features_file.writerow(features_names)\n",
    "    for idx, raw_feature in enumerate(train_audio_features_all):\n",
    "        row = []\n",
    "        for i, f in enumerate(raw_feature):\n",
    "            if i == 0:\n",
    "                row.append(f)\n",
    "                print(idx, f)\n",
    "            elif i == 1:\n",
    "                row.append([sum(f), len(f)])\n",
    "            else:\n",
    "                row.append(f.tolist())\n",
    "        features_file.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported csv file can be found [here]() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
